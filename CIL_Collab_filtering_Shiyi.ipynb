{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Based Collaborative Filtering Aloghrithm \n",
    "\n",
    "# for Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pre-define functions to be used **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, bmat\n",
    "from time import time\n",
    "from os.path import isfile\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# The csv processing functions are wrapped in helper.py\n",
    "from helper import csv_parse, write_submission\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMS(pred, true):\n",
    "    rms = np.sqrt(np.sum((pred-true)**2)/len(pred))\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the training data and pre-process the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in processed csv_train file: Success!\n"
     ]
    }
   ],
   "source": [
    "# Loading the train data\n",
    "train_csv_raw = './cil-collab-filtering-2018/data_train.csv'\n",
    "csv_train = './data_train_post.csv'\n",
    "if isfile(csv_train):\n",
    "    print('Read in processed csv_train file: Success!')\n",
    "    df_train = pd.read_csv(csv_train)\n",
    "else:\n",
    "    df_train = csv_parse(train_csv_raw, csv_train)\n",
    "\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creat a baseline solution \n",
    "\n",
    "We create a baseline solution by setting the missing values to the average over all observed ratings for a particular item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the size of the training data\n",
    "global user_N, item_N \n",
    "user_N = 100000\n",
    "item_N = 1000\n",
    "    \n",
    "# Prepare baseline matrix \n",
    "# Calculate mean rating for every single item\n",
    "mean_per_item = df_train.groupby('col_id')['Prediction'].mean().as_matrix()\n",
    "\n",
    "# Form A with sparse matrix (more efficient)\n",
    "A = coo_matrix((df_train['Prediction'], \n",
    "                (df_train['row_id']-1, df_train['col_id']-1))\n",
    "              ).todense()\n",
    "A = A + mean_per_item \n",
    "A[df_train['row_id']-1, df_train['col_id']-1] = df_train['Prediction']\n",
    "\n",
    "# write_submission(A, dst='./cil-collab-filtering-2018/submission_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: SVD Decomposition\n",
    "\n",
    "Compute the SVD Decompostion of the training matrix with the imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of userValue matrix: 10000 x 1000\n",
      "Shape of itemValue matrix: 1000 x 1000\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on matrix A\n",
    "u, s, vh = np.linalg.svd(A, full_matrices=False)\n",
    "s_diag = np.diag(np.sqrt(s))\n",
    "u_prime = np.dot(u, s_diag)\n",
    "vh_prime = np.dot(vh,s_diag)\n",
    "\n",
    "print('Shape of userValue matrix: %d x %d' % u_prime.shape)\n",
    "print('Shape of itemValue matrix: %d x %d' % vh_prime.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model Selection **: Select a number k of eigenvalues to be used and truncate U and V accordingly. Evaluate the model performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rms = []\n",
    "# k_range = np.arange(1, 201, 10)\n",
    "\n",
    "# for k in k_range:\n",
    "#     A_pred = np.dot(u_prime[:, 0:k], vh_prime[0:k, :])\n",
    "#     df_train['my_Prediction'] = A_pred[df_train['row_id']-1, df_train['col_id']-1].T\n",
    "#     rms.append(RMS(df_train['my_Prediction'], df_train['Prediction']))\n",
    "    \n",
    "# plt.plot(k_range, rms)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Step 3: Make Prediction \n",
    "\n",
    "Make prediction about the missing values with gradient descent algorithms\n",
    "\n",
    "** Algorithm 1: Stocastic Gradient Descent **\n",
    "\n",
    "The misfit function here is given as: \n",
    "$$ \\min_{q,p}\\left.\\{ \\sum_{u,i\\in\\kappa}{(r_{ui}-q_i^Tp_u)^2} + \\lambda(||q_i||^2 + ||p_u||^2)\\right.\\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misfit_func(r, userValue, itemValue, lamda, df_train):\n",
    "    global user_N, item_N\n",
    "    \n",
    "    r_pred = np.dot(userValue, itemValue)\n",
    "    df_train['my_Prediction'] = r_pred[df_train['row_id']-1, df_train['col_id']-1].T\n",
    "    err = df_train['Prediction'] - df_train['my_Prediction']\n",
    "    loss = (err **2).sum()# + lamda * (norm(userValue, axis=1)+norm(itemValue, axis=0))\n",
    "    err_matrix = coo_matrix((err, (df_train['row_id']-1, df_train['col_id']-1))) \n",
    "    return loss, err_matrix\n",
    "\n",
    "def update_function(itemValue, userValue, lamda, err, gamma):\n",
    "    \n",
    "    global user_N, item_N\n",
    "    \n",
    "    paras = np.vstack((itemValue.T, userValue))\n",
    "    \n",
    "    coeff_matrix = bmat([[None, err.T], [err, None]]).toarray()\n",
    "#     coeff_matrix[0:1000, 0:1000] = -lamda\n",
    "#     coeff_matrix[1000:, 1000:] = -lamda\n",
    "    \n",
    "    new_paras = gamma * np.dot(coeff_matrix, paras) + paras\n",
    "    \n",
    "    new_itemValue = new_paras[0:item_N, :]\n",
    "    new_userValue = new_paras[item_N:, :]\n",
    "    \n",
    "    return new_itemValue.T, new_userValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_select = 10      # Turncation number \n",
    "gamma = -0.001       # Learning rate\n",
    "max_iter = 1000      # Maximum iteration\n",
    "misfit = []          # store the misfit value\n",
    "epsilon = 1e-3       # accept condition\n",
    "\n",
    "lamda=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10, 1000)\n"
     ]
    }
   ],
   "source": [
    "i_iter = 1\n",
    "tic = time()\n",
    "\n",
    "userValue = u_prime[:, 0:k_select]\n",
    "itemValue = vh_prime[0:k_select, :]\n",
    "print(userValue.shape, itemValue.shape)\n",
    "\n",
    "user_id = df_train['row_id']-1\n",
    "item_id = df_train['col_id']-1\n",
    "\n",
    "r = df_train['Prediction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "(1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "loss, err = misfit_func(r, userValue, itemValue, lamda, df_train)\n",
    "print('%.2e' % loss)\n",
    "print(err.toarray().T.shape)\n",
    "while (i_iter <= max_iter and loss > epsilon):\n",
    "    \n",
    "    itemValue, userValue = update_function(itemValue, userValue, lamda, err, gamma)\n",
    "    loss, err = misfit_func(r, userValue, itemValue, lamda, df_train)\n",
    "        \n",
    "    if i_iter % 2 == 0:\n",
    "        toc = time()\n",
    "        print('Iteration: %d, Misfit: %.2e, Average time per iteration: %.4f' % \n",
    "              (i_iter, loss, (toc-tic)/i_iter))\n",
    "    \n",
    "    i_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(userValue.shape, itemValue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
