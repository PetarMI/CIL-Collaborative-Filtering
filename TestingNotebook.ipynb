{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import math\n",
    "import data_handler as dh\n",
    "import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make all definitions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_item_mean(ratings: np.ndarray, item_data: np.ndarray):\n",
    "    \"\"\" Calculate a mean based of data variance and offsets\n",
    "\n",
    "    :param ratings: all ratings in the training data\n",
    "    :param item_data: data related to the item whose mean we are calculating\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    overall_mean = np.mean(ratings)\n",
    "    overall_variance = np.var(ratings)\n",
    "\n",
    "    item_sum = np.sum(item_data)\n",
    "    item_variance = np.var(item_data)\n",
    "    item_size = len(item_data)\n",
    "    var_ratio = item_variance / overall_variance\n",
    "\n",
    "    item_mean = (overall_mean * var_ratio + item_sum) / (var_ratio + item_size)\n",
    "    return item_mean\n",
    "\n",
    "\n",
    "def calculate_all_means(df_data: pd.DataFrame):\n",
    "    \"\"\" Calculate the mean rating per movie as well as the average user offset\n",
    "\n",
    "    :param df_data: All training data\n",
    "    :return: Arrays containing the calculated values for each user and movie\n",
    "    \"\"\"\n",
    "    user_ids = (df_data['row_id'] - 1).values\n",
    "    movie_ids = (df_data['col_id'] - 1).values\n",
    "    ratings = df_data['Prediction'].values\n",
    "\n",
    "    print(\"Calculating movie average ratings\")\n",
    "    tic = time()\n",
    "    # find the average ratings for each movie\n",
    "    movie_ratings = []\n",
    "    for m in range(0, paths.num_movies):\n",
    "        # find entries and then ratings for movie m\n",
    "        m_entries = np.where(np.equal(movie_ids, m))[0]\n",
    "        m_ratings = ratings[m_entries]\n",
    "        movie_mean = calculate_item_mean(ratings, m_ratings)\n",
    "        movie_ratings.append(movie_mean)\n",
    "    toc = time()\n",
    "    print(toc - tic)\n",
    "\n",
    "    print(\"Calculating rating offsets\")\n",
    "    tic = time()\n",
    "    # find the offset of each rating\n",
    "    rating_offsets = []\n",
    "    for r in range(0, len(ratings)):\n",
    "        offset = ratings[r] - movie_ratings[movie_ids[r]]\n",
    "        rating_offsets.append(offset)\n",
    "    toc = time()\n",
    "    print(toc - tic)\n",
    "\n",
    "    print(\"Calculating user average offsets\")\n",
    "    tic = time()\n",
    "    rating_offsets = np.asarray(rating_offsets)\n",
    "    user_offsets = []\n",
    "    # calculate the mean offset for each user\n",
    "    for u in range(0, paths.num_users):\n",
    "        # find all entries for user u and then all their ratings\n",
    "        u_entries = np.where(np.equal(user_ids, u))[0]\n",
    "        u_offsets = rating_offsets[u_entries]\n",
    "        user_mean = calculate_item_mean(ratings, u_offsets)\n",
    "        user_offsets.append(user_mean)\n",
    "    toc = time()\n",
    "    print(toc - tic)\n",
    "\n",
    "    return {\"mean_movie_rating\" : movie_ratings, \"mean_user_offsets\" : user_offsets}\n",
    "\n",
    "\n",
    "def predict_initial_rating(mean_predictions: dict, user: int, movie: int):\n",
    "    \"\"\" Get a prediction rating for a user-movie pair\n",
    "    based purely on the movie average rating and user offset\n",
    "\n",
    "    :param mean_predictions: data with all the averages\n",
    "    :param user: user index\n",
    "    :param movie: movie index\n",
    "    :return: the predicted rating\n",
    "    \"\"\"\n",
    "    movie_ratings = mean_predictions[\"mean_movie_rating\"]\n",
    "    user_offsets = mean_predictions[\"mean_user_offsets\"]\n",
    "    rating = movie_ratings[movie] + user_offsets[user]\n",
    "    rating = min(paths.max_rating, rating)\n",
    "    rating = max(paths.min_rating, rating)\n",
    "\n",
    "    return rating\n",
    "\n",
    "\n",
    "# make a prediction for a single user-movie pair\n",
    "def make_prediction(mean_predictions, user_features, movie_features, bu, bm, user, movie):\n",
    "    rating = predict_initial_rating(mean_predictions, user, movie)\n",
    "    rating += sum(user_features[user] * movie_features[:, movie]) + bu[user] + bm[movie]\n",
    "\n",
    "    return rating\n",
    "\n",
    "\n",
    "def calculate_rmse(mean_predictions, user_features, movie_features, bu, bm, test_samples):\n",
    "    \"\"\" Calculate the rmse w.r.t. every sample in the testing set \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for sample in test_samples:\n",
    "        rating = sample[paths.rating_id]\n",
    "        predicted_rating = make_prediction(mean_predictions, user_features, movie_features,\n",
    "                                           bu, bm, sample[paths.user_id], sample[paths.movie_id])\n",
    "        err = rating - predicted_rating\n",
    "        errors.append(err*err)\n",
    "\n",
    "    rmse = math.sqrt(np.mean(errors))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def train(k, mean_predictions, user_features, movie_features, bu, bm, train_data, test_data):\n",
    "    rmse: float = calculate_rmse(mean_predictions, user_features, movie_features, bu, bm, test_data)\n",
    "    prev_rmse: float = rmse\n",
    "    print(\"Starting rmse: {0}\".format(rmse))\n",
    "    \n",
    "    for feature in range(0, k):\n",
    "        print(\"Training feature {0}\".format(feature))\n",
    "        user_features[feature] = 0.1\n",
    "        movie_features[:, feature] = 0.1\n",
    "\n",
    "        tic = time()\n",
    "        # train the feature\n",
    "        for i in range(1, 1000):\n",
    "            for sample in train_data:\n",
    "                user = sample[paths.user_id]\n",
    "                movie = sample[paths.movie_id]\n",
    "\n",
    "                mf = movie_features[:, movie][feature]\n",
    "                uf = user_features[user][feature]\n",
    "\n",
    "                predicted_rating = make_prediction(mean_predictions, user_features, movie_features,\n",
    "                                                   bu, bm, user, movie)\n",
    "                err = sample[paths.rating_id] - predicted_rating\n",
    "\n",
    "                # update the features\n",
    "                user_features[user][feature] += paths.learning_rate * (err * mf - paths.lambda_term * uf)\n",
    "                movie_features[:, movie][feature] += paths.learning_rate * (err * uf - paths.lambda_term * mf)\n",
    "\n",
    "                bu[user] += paths.learning_rate * (err - paths.lambda_term * bu[user])\n",
    "                bm[movie] += paths.learning_rate * (err - paths.lambda_term * bm[movie])\n",
    "\n",
    "            rmse = calculate_rmse(mean_predictions, user_features, movie_features, bu, bm, test_data)\n",
    "            toc = time()\n",
    "            iter_time = (toc - tic) / i\n",
    "            print('Iteration: %d, Misfit: %.8f, Improvement: %.8f, Time: %.3f'\n",
    "                  % (i, rmse, prev_rmse - rmse, iter_time))\n",
    "            if (rmse > prev_rmse and i > 5):\n",
    "                break\n",
    "            prev_rmse = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write stuff we want to test here (train function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing data\")\n",
    "df_data: pd.DataFrame = dh.read_data(paths.total_dataset_location)\n",
    "data_dict: dict = dh.split_original_data(df_data, 0.1)\n",
    "\n",
    "df_train_data: pd.DataFrame = data_dict[\"train_data\"]\n",
    "df_test_data: pd.DataFrame = data_dict[\"test_data\"]\n",
    "\n",
    "train_samples: np.ndarray = dh.df_as_array(df_train_data)\n",
    "test_samples: np.ndarray = dh.df_as_array(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean predictions\n",
      "Calculating movie average ratings\n",
      "6.848834037780762\n",
      "Calculating rating offsets\n",
      "4.6001904010772705\n",
      "Calculating user average offsets\n",
      "66.53981423377991\n",
      "77.99502110481262\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating mean predictions\")\n",
    "tic = time()\n",
    "mean_predictions = calculate_all_means(df_train_data)\n",
    "toc = time()\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables needed for training\n",
    "k = 10\n",
    "bu = np.zeros(paths.num_users)\n",
    "bm = np.zeros(paths.num_movies)\n",
    "user_features = np.zeros((paths.num_users, k))\n",
    "movie_features = np.zeros((k, paths.num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rmse: 0.9993717095178094\n",
      "Training feature 0\n",
      "Iteration: 1, Misfit: 0.99880673, Improvement: 0.00056498, Time: 23.327\n",
      "Iteration: 2, Misfit: 0.99869303, Improvement: 0.00011369, Time: 23.410\n",
      "Iteration: 3, Misfit: 0.99864143, Improvement: 0.00005160, Time: 23.392\n",
      "Iteration: 4, Misfit: 0.99860971, Improvement: 0.00003172, Time: 23.424\n",
      "Iteration: 5, Misfit: 0.99858764, Improvement: 0.00002207, Time: 23.402\n",
      "Iteration: 6, Misfit: 0.99857147, Improvement: 0.00001617, Time: 23.430\n",
      "Iteration: 7, Misfit: 0.99855936, Improvement: 0.00001212, Time: 23.429\n",
      "Iteration: 8, Misfit: 0.99855018, Improvement: 0.00000917, Time: 23.441\n",
      "Iteration: 9, Misfit: 0.99854322, Improvement: 0.00000696, Time: 23.434\n",
      "Iteration: 10, Misfit: 0.99853795, Improvement: 0.00000527, Time: 23.450\n",
      "Iteration: 11, Misfit: 0.99853399, Improvement: 0.00000396, Time: 23.472\n",
      "Iteration: 12, Misfit: 0.99853104, Improvement: 0.00000295, Time: 23.471\n",
      "Iteration: 13, Misfit: 0.99852890, Improvement: 0.00000215, Time: 23.454\n",
      "Iteration: 14, Misfit: 0.99852738, Improvement: 0.00000152, Time: 23.450\n",
      "Iteration: 15, Misfit: 0.99852635, Improvement: 0.00000102, Time: 23.444\n",
      "Iteration: 16, Misfit: 0.99852572, Improvement: 0.00000063, Time: 23.447\n",
      "Iteration: 17, Misfit: 0.99852540, Improvement: 0.00000032, Time: 23.440\n",
      "Iteration: 18, Misfit: 0.99852532, Improvement: 0.00000008, Time: 23.450\n",
      "Iteration: 19, Misfit: 0.99852544, Improvement: -0.00000012, Time: 23.449\n",
      "Training feature 1\n",
      "Iteration: 1, Misfit: 0.99852571, Improvement: -0.00000039, Time: 23.520\n",
      "Iteration: 2, Misfit: 0.99852610, Improvement: -0.00000039, Time: 23.551\n",
      "Iteration: 3, Misfit: 0.99852658, Improvement: -0.00000048, Time: 23.518\n",
      "Iteration: 4, Misfit: 0.99852714, Improvement: -0.00000055, Time: 23.513\n",
      "Iteration: 5, Misfit: 0.99852774, Improvement: -0.00000061, Time: 23.494\n",
      "Iteration: 6, Misfit: 0.99852839, Improvement: -0.00000065, Time: 23.479\n",
      "Training feature 2\n",
      "Iteration: 1, Misfit: 0.99852906, Improvement: -0.00000132, Time: 23.387\n",
      "Iteration: 2, Misfit: 0.99852976, Improvement: -0.00000070, Time: 23.484\n",
      "Iteration: 3, Misfit: 0.99853046, Improvement: -0.00000071, Time: 23.427\n",
      "Iteration: 4, Misfit: 0.99853118, Improvement: -0.00000071, Time: 23.408\n",
      "Iteration: 5, Misfit: 0.99853190, Improvement: -0.00000072, Time: 23.423\n",
      "Iteration: 6, Misfit: 0.99853261, Improvement: -0.00000071, Time: 23.457\n",
      "Training feature 3\n",
      "Iteration: 1, Misfit: 0.99853330, Improvement: -0.00000141, Time: 23.472\n",
      "Iteration: 2, Misfit: 0.99853400, Improvement: -0.00000070, Time: 23.679\n",
      "Iteration: 3, Misfit: 0.99853470, Improvement: -0.00000069, Time: 23.640\n"
     ]
    }
   ],
   "source": [
    "train(k, mean_predictions, user_features, movie_features, bu, bm, train_samples, test_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
