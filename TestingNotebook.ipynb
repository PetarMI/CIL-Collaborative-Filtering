{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_handler as dh\n",
    "import svd_approach as svd_base\n",
    "import paths\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make all definitions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO is it gonna be quicker if we multiply just training data in a for loop\n",
    "def make_predictions(P: np.ndarray, Q: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Make the prediction based on the approximation matrices\n",
    "\n",
    "    :param P: Approximation matrix\n",
    "    :param Q: Approximation matrix\n",
    "    :return predictions: The approximation matrix we get after dot product of truncated U and V\n",
    "    \"\"\"\n",
    "    prediction_matrix: np.ndarray = np.dot(P, Q)\n",
    "    return prediction_matrix\n",
    "\n",
    "\n",
    "# TODO annotate return type\n",
    "def init_baseline(df_data: pd.DataFrame):\n",
    "    \"\"\" Prepare the baseline for first iteration of SGD\n",
    "        Baseline is the approximation matrices inferred from the SVD approach\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    A: np.ndarray = svd_base.fill_averages(df_data)\n",
    "    U, Vh = svd_base.perform_svd(A)\n",
    "\n",
    "    return U, Vh\n",
    "\n",
    "\n",
    "# TODO annotate return type\n",
    "def set_features(k: int, u: np.ndarray, vh: np.ndarray):\n",
    "    \"\"\" Choose how many features to use\n",
    "\n",
    "    :param k: Number of features\n",
    "    :param u: Approximation matrix\n",
    "    :param vh: Approximation matrix\n",
    "    :return: The two matrices\n",
    "    \"\"\"\n",
    "    u_prime = u[:, :k]\n",
    "    vh_prime = vh[:k, :]\n",
    "\n",
    "    return u_prime, vh_prime\n",
    "\n",
    "def sgd_update(train_samples, U, M, alpha, l):\n",
    "    \"\"\" Perform the update step of SGD\n",
    "\n",
    "    :param train_samples: all samples we are training w.r.t\n",
    "    :param U: Approximation matrix\n",
    "    :param M: Approximation matrix\n",
    "    :param l: regularizer term\n",
    "    :return: updated approximation matrices\n",
    "    \"\"\"\n",
    "    for i in np.random.permutation(len(train_samples)):\n",
    "        user = train_samples[i][paths.user_id]\n",
    "        movie = train_samples[i][paths.movie_id]\n",
    "        rating = train_samples[i][paths.rating_id]\n",
    "\n",
    "        prediction = np.dot(U[user, :], M[:, movie])\n",
    "        err = rating - prediction\n",
    "\n",
    "        # update step\n",
    "        U[user, :] += alpha * (err * M[:, movie] - l * U[user, :])\n",
    "        M[:, movie] += alpha * (err * U[user, :] - l * M[:, movie])\n",
    "\n",
    "        return U, M\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write stuff we want to test here (train function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\n",
      "Initializing state of approximation matrices\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing data\")\n",
    "df_data: pd.DataFrame = dh.read_data(paths.total_dataset_location)\n",
    "data_dict: dict = dh.split_original_data(df_data, 0.1)\n",
    "\n",
    "df_train_data: pd.DataFrame = data_dict[\"train_data\"]\n",
    "df_test_data: pd.DataFrame = data_dict[\"test_data\"]\n",
    "\n",
    "print(\"Initializing state of approximation matrices\")\n",
    "# get the starting P and Q matrices\n",
    "k = 10\n",
    "u, vh = init_baseline(df_train_data)\n",
    "P, Q = set_features(k, u, vh)\n",
    "assert(P.shape == (paths.num_users, k))\n",
    "assert(Q.shape == (k, paths.num_movies))\n",
    "\n",
    "train_samples: np.ndarray = dh.df_as_array(df_train_data)\n",
    "alpha: float = paths.learning_rate\n",
    "lambda_term: float = paths.lambda_term\n",
    "i_iter = 1\n",
    "tic = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SGD algorithm\n",
      "Iteration: 100, Misfit: 1.00764\n",
      "Average time per iteration: 0.4635\n",
      "Iteration: 200, Misfit: 1.00763\n",
      "Average time per iteration: 0.2995\n",
      "Iteration: 300, Misfit: 1.00762\n",
      "Average time per iteration: 0.2444\n",
      "Iteration: 400, Misfit: 1.00761\n",
      "Average time per iteration: 0.2169\n",
      "Iteration: 500, Misfit: 1.00761\n",
      "Average time per iteration: 0.2010\n",
      "Iteration: 600, Misfit: 1.00760\n",
      "Average time per iteration: 0.1908\n",
      "Iteration: 700, Misfit: 1.00759\n",
      "Average time per iteration: 0.1827\n",
      "Iteration: 800, Misfit: 1.00759\n",
      "Average time per iteration: 0.1765\n",
      "Iteration: 900, Misfit: 1.00759\n",
      "Average time per iteration: 0.1717\n",
      "Iteration: 1000, Misfit: 1.00759\n",
      "Average time per iteration: 0.1680\n",
      "Iteration: 1100, Misfit: 1.00758\n",
      "Average time per iteration: 0.1651\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-18bf1ef40b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# check results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprediction_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4226072c9c45>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(P, Q)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mapproximation\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mget\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mdot\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtruncated\u001b[0m \u001b[0mU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprediction_matrix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting SGD algorithm\")\n",
    "U = P\n",
    "M = Q\n",
    "while(i_iter <= paths.sgd_max_iteration):\n",
    "        # perform update steps\n",
    "        U, M = sgd_update(train_samples, U, M, alpha, lambda_term)\n",
    "\n",
    "        # check results\n",
    "        prediction_matrix = make_predictions(U, M)\n",
    "        rmse = svd_base.calc_rmse(df_test_data, prediction_matrix)\n",
    "\n",
    "        toc = time()\n",
    "        i_iter += 1\n",
    "        if i_iter % 100 == 0:\n",
    "            toc = time()\n",
    "            print('Iteration: %d, Misfit: %.5f' % (i_iter, rmse))\n",
    "            print('Average time per iteration: %.4f' % ((toc - tic) / i_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_as_array(df_train_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
